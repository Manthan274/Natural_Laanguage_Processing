{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interesting Tweet Analysis\n",
    "\n",
    "Twitter provides API to extract the tweet content based on the search keyword or id or user. Tweet content includes various numerical as well as textual parameters such as tweet text, like count, retweet count, etc. It does not provide the direct reply message content of any tweet or the chat based export of any tweet. For this user have to use different web scrapping methods (PHP, HTML or javascript based). And that will be a very big and time-consuming project.\n",
    "\n",
    "Accordingly, in below assignment, I have built a ML model to extract the 'n' number of interesting tweet for any keyword or hashtag. I have used two different techniques to train two different models and finally combine them for the better result. These models are trained using limited trained data and without taking help of any content expert. So the accuracy of a model will not be much impressive. All other explanations are mentioned along with the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet scraping\n",
    "\n",
    "Twitter API only provides a limited number of tweets per pool as well as there is a restriction of 15 min for total pooling. So for complete tweet extraction, I am using web scraping tool rather than Twitter API.\n",
    "\n",
    "The limitation of this tool is that it only provides limited details such as tweet text, username, likes, retweets, etc. But it does not provide you with the detail of user such as a number of followers, verified or not, etc. So after analysing scrapped tweets, we will use its ids to extract all the relevant information for further modelling.\n",
    "\n",
    "Here I have scrapped all the tweets of \"W Brom vs Liverpool\" premier league match with a hashtag <b>'#WBALIV'.\n",
    "\n",
    "##### Note: After extracting tweets, I have removed my Twitter API credential for privacy issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API credentials\n",
    "#removed Twitter API credential for privacy issues\n",
    "\n",
    "consumer_key = '#'\n",
    "consumer_secret = '#'\n",
    "access_token = '#-#'\n",
    "access_token_secret = '#'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapping the tweet with web scrapper\n",
    "#scrapping query has been marked as a comment to avoid it from running every time.\n",
    "\n",
    "from twitterscraper import query_tweets\n",
    "import datetime as dt\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "    #list_of_tweets = query_tweets(\"#WBALIV\", 10000, begindate=dt.date(2018,4,20), enddate=dt.date.today(), lang='en')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the retrieved tweets to the screen:\n",
    "\n",
    "def populate_tweet_df(tweets):\n",
    "    data = pd.DataFrame()\n",
    "    data['id'] = list(map(lambda tweet: int(tweet.id), tweets))\n",
    "    data['fullname'] = list(map(lambda tweet: tweet.fullname, tweets))\n",
    "    data['user'] = list(map(lambda tweet: tweet.user, tweets))\n",
    "    data['text'] = list(map(lambda tweet: tweet.text, tweets))\n",
    "    data['likes'] = list(map(lambda tweet: int(tweet.likes), tweets))\n",
    "    data['retweets'] = list(map(lambda tweet: int(tweet.retweets), tweets))  \n",
    "    data['replies'] = list(map(lambda tweet: int(tweet.replies), tweets)) \n",
    "    data['timestamp'] = list(map(lambda tweet: tweet.timestamp, tweets))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the tweets as pickle object\n",
    "\n",
    "#with open(\"tweets.pickle\", \"wb\") as f:\n",
    "        #pickle.dump(list_of_tweets, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweets.pickle', 'rb') as handle:\n",
    "    tweets = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting tweet object into dataframe\n",
    "\n",
    "tweet_data=populate_tweet_df(tweets).drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fullname</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>replies</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>987680042141601793</td>\n",
       "      <td>Alan Shearer</td>\n",
       "      <td>alanshearer</td>\n",
       "      <td>Magnificent @22mosalah    @premierleague goals...</td>\n",
       "      <td>9213</td>\n",
       "      <td>2332</td>\n",
       "      <td>101</td>\n",
       "      <td>2018-04-21 13:10:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>987679304241831941</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>premierleague</td>\n",
       "      <td>Mo Salah has scored 31 #PL goals this season –...</td>\n",
       "      <td>5311</td>\n",
       "      <td>1700</td>\n",
       "      <td>96</td>\n",
       "      <td>2018-04-21 13:07:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>987682515057102848</td>\n",
       "      <td>Liverpool FC</td>\n",
       "      <td>LFC</td>\n",
       "      <td>The points are shared.\\n\\n#WBALIV pic.twitter....</td>\n",
       "      <td>4285</td>\n",
       "      <td>1439</td>\n",
       "      <td>550</td>\n",
       "      <td>2018-04-21 13:20:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>987682605301665799</td>\n",
       "      <td>Premier League</td>\n",
       "      <td>premierleague</td>\n",
       "      <td>The Baggies refuse to give up and are rewarded...</td>\n",
       "      <td>1908</td>\n",
       "      <td>566</td>\n",
       "      <td>105</td>\n",
       "      <td>2018-04-21 13:20:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>987680971142172672</td>\n",
       "      <td>Liverpool FC</td>\n",
       "      <td>LFC</td>\n",
       "      <td>88: Goal for West Brom. Rondon.\\n\\n[2-2]\\n\\n#W...</td>\n",
       "      <td>2119</td>\n",
       "      <td>527</td>\n",
       "      <td>455</td>\n",
       "      <td>2018-04-21 13:14:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id        fullname           user  \\\n",
       "0  987680042141601793    Alan Shearer    alanshearer   \n",
       "1  987679304241831941  Premier League  premierleague   \n",
       "2  987682515057102848    Liverpool FC            LFC   \n",
       "3  987682605301665799  Premier League  premierleague   \n",
       "4  987680971142172672    Liverpool FC            LFC   \n",
       "\n",
       "                                                text  likes  retweets  \\\n",
       "0  Magnificent @22mosalah    @premierleague goals...   9213      2332   \n",
       "1  Mo Salah has scored 31 #PL goals this season –...   5311      1700   \n",
       "2  The points are shared.\\n\\n#WBALIV pic.twitter....   4285      1439   \n",
       "3  The Baggies refuse to give up and are rewarded...   1908       566   \n",
       "4  88: Goal for West Brom. Rondon.\\n\\n[2-2]\\n\\n#W...   2119       527   \n",
       "\n",
       "   replies           timestamp  \n",
       "0      101 2018-04-21 13:10:46  \n",
       "1       96 2018-04-21 13:07:50  \n",
       "2      550 2018-04-21 13:20:36  \n",
       "3      105 2018-04-21 13:20:58  \n",
       "4      455 2018-04-21 13:14:28  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validating the tweets\n",
    "\n",
    "tweet_data.sort_values(by='retweets', ascending=False).reset_index(drop=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting ids of the tweets having more than 1 likes or retweets\n",
    "\n",
    "ids=list(tweet_data[(tweet_data['retweets']>1) | (tweet_data['likes']>1)]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using tweepy to extract the complete details of above-extracted ids\n",
    "\n",
    "import tweepy\n",
    "\n",
    "#tweets = twapi.statuses_lookup(id_=idlist, include_entities=True, trim_user=False)\n",
    "\n",
    "#This does not works with extented tweet texts (280 character limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating loop to extract individual tweet from each id with more than one (1) likes or retweet\n",
    "\n",
    "#all_tweets=[]\n",
    "#for i in range(len(ids)):\n",
    "    #x=api.get_status(ids[i], tweet_mode='extended')._json\n",
    "    #all_tweets.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to transfer tweepy output into a dataframe for better preprocessing and modelling\n",
    "\n",
    "def get_tweet_df(tweets):    \n",
    "    tw = pd.DataFrame()\n",
    " \n",
    "    tw['text'] = list(map(lambda tweet: tweet['full_text'], tweets))\n",
    "    tw['retweet_count'] = list(map(lambda tweet: tweet['retweet_count'], tweets))\n",
    "    tw['favorite_count'] = list(map(lambda tweet: tweet['favorite_count'], tweets))  \n",
    "    tw['lang'] = list(map(lambda tweet: tweet['lang'], tweets))\n",
    "    \n",
    "    #User Details\n",
    "    tw['user_screen_name'] = list(map(lambda tweet: tweet['user']['screen_name'], tweets))\n",
    "    tw['user_verified'] = list(map(lambda tweet: tweet['user']['verified'], tweets))\n",
    "    tw['user_followers_count'] = list(map(lambda tweet: tweet['user']['followers_count'], tweets))\n",
    "    tw['user_favourites_count'] = list(map(lambda tweet: tweet['user']['favourites_count'], tweets))\n",
    "    tw['user_listed_count'] = list(map(lambda tweet: tweet['user']['statuses_count'], tweets))\n",
    "    tw['user_statuses_count'] = list(map(lambda tweet: tweet['user']['statuses_count'], tweets))\n",
    "    \n",
    "    return tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save tweets dataframe into excel format for tweet classification\n",
    "\n",
    "#get_tweet_df(all_tweets).to_excel('all_tweet.xlsx', index_label=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "\n",
    "In first model we will extract the notable tweets with general criteria like retweet_count > 1 & favorite_count > 4. Then we manually tag the interesting tweet for interesting categories (~360 tweets).\n",
    "\n",
    "Then we preprocess the tweet text for modelling. We will train the model using Tf-IDF vectoriser and LinearSVC algorithm.\n",
    "Based on the trained model, we will predict the interesting category for all of the notable tweets (~710). \n",
    "\n",
    "Here we are using very less manually tagged training data so accuracy might not be very good. We can get better accuracy with larger training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_excel('all_tweet.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Marking tweet as interesting if mentioned criteria are followed\n",
    "\n",
    "for i in range(len(train)):\n",
    "    if (train.loc[i,'user_verified']==False) & (train.loc[i,'retweet_count']>10) & (train.loc[i,'favorite_count']>10):\n",
    "        train.loc[i,'interesting']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting tweets with more than 1 retweet or 4 likes for manually marking interesting tag\n",
    "\n",
    "train_rel=train[(train['retweet_count']>1) | (train['favorite_count']>4)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_rel.to_excel('all_tweet_train.xlsx', index_label=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>lang</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>user_listed_count</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>interesting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game day make it ⚽️#31 Mo #WBALIV https://t.co...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>en</td>\n",
       "      <td>O1Paul</td>\n",
       "      <td>False</td>\n",
       "      <td>7758</td>\n",
       "      <td>12008</td>\n",
       "      <td>1395</td>\n",
       "      <td>1395</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>☁️9️\\n\\n@LFC are unbeaten in their last nine #...</td>\n",
       "      <td>296</td>\n",
       "      <td>2467</td>\n",
       "      <td>en</td>\n",
       "      <td>premierleague</td>\n",
       "      <td>True</td>\n",
       "      <td>17811702</td>\n",
       "      <td>999</td>\n",
       "      <td>91545</td>\n",
       "      <td>91545</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Early risers, we've got another one at 730AM t...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>en</td>\n",
       "      <td>LFCAtlanta</td>\n",
       "      <td>False</td>\n",
       "      <td>2683</td>\n",
       "      <td>4218</td>\n",
       "      <td>31447</td>\n",
       "      <td>31447</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#PL 🏴󠁧󠁢󠁥󠁮󠁧󠁿⚽\\nWest Bromwich Albion 🆚 Liverpool...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>en</td>\n",
       "      <td>JugadaDepCL</td>\n",
       "      <td>False</td>\n",
       "      <td>6585</td>\n",
       "      <td>978</td>\n",
       "      <td>13554</td>\n",
       "      <td>13554</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>West Brom vs Liverpool: Preview, Team News, an...</td>\n",
       "      <td>16</td>\n",
       "      <td>36</td>\n",
       "      <td>en</td>\n",
       "      <td>BloodsugarNatz</td>\n",
       "      <td>False</td>\n",
       "      <td>7252</td>\n",
       "      <td>19824</td>\n",
       "      <td>9590</td>\n",
       "      <td>9590</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  retweet_count  \\\n",
       "0  Game day make it ⚽️#31 Mo #WBALIV https://t.co...              3   \n",
       "1  ☁️9️\\n\\n@LFC are unbeaten in their last nine #...            296   \n",
       "2  Early risers, we've got another one at 730AM t...              1   \n",
       "3  #PL 🏴󠁧󠁢󠁥󠁮󠁧󠁿⚽\\nWest Bromwich Albion 🆚 Liverpool...              8   \n",
       "4  West Brom vs Liverpool: Preview, Team News, an...             16   \n",
       "\n",
       "   favorite_count lang user_screen_name  user_verified  user_followers_count  \\\n",
       "0              22   en           O1Paul          False                  7758   \n",
       "1            2467   en    premierleague           True              17811702   \n",
       "2               5   en       LFCAtlanta          False                  2683   \n",
       "3               5   en      JugadaDepCL          False                  6585   \n",
       "4              36   en   BloodsugarNatz          False                  7252   \n",
       "\n",
       "   user_favourites_count  user_listed_count  user_statuses_count  interesting  \n",
       "0                  12008               1395                 1395        False  \n",
       "1                    999              91545                91545         True  \n",
       "2                   4218              31447                31447        False  \n",
       "3                    978              13554                13554        False  \n",
       "4                  19824               9590                 9590         True  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the manually marked tweet data\n",
    "\n",
    "df=pd.read_excel('all_tweet_tagged.xlsx', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    '''\n",
    "    Utility function to clean the text in a tweet by removing \n",
    "    links and special characters using regex.\n",
    "    '''\n",
    "    clean_tweets= ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split()).lower()\n",
    "    \n",
    "    return clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                        game day make it 31 mo wbaliv\n",
      "1    9 are unbeaten in their last nine pl meetings ...\n",
      "2    early risers we ve got another one at 730am to...\n",
      "3    pl west bromwich albion liverpool relatos come...\n",
      "4    west brom vs liverpool preview team news and w...\n",
      "5    tomorrow west brom v liverpool ko 12 30pm it s...\n",
      "6    here s how ray would lineup the lfc side for w...\n",
      "7    looking forward to a trip to the baggies tomor...\n",
      "8    the latest news from both sides ahead of our t...\n",
      "9    before the big 1 next wk need saturday ritual ...\n",
      "Name: clean_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['clean_text']=df['text'].apply(lambda x: clean_tweet(x))\n",
    "\n",
    "print(df['clean_text'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text preprocessing for stopwords removal, lemmatization and spelling correction\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import Word\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def tweet_preprocessing(tweet):\n",
    "    \n",
    "    stopwords=  \" \".join([word for word in tweet.split() if word not in stop_words])\n",
    "    lemmatize= \" \".join([Word(word).lemmatize() for word in stopwords.split()])\n",
    "    clean_tweet= str(TextBlob(lemmatize).correct())\n",
    "    \n",
    "    return clean_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                           game day make 31 mo wbaliv\n",
      "1           9 beaten last nine ll meeting we do wbaliv\n",
      "2    early riser got another one 730am tomorrow mor...\n",
      "3    ll west bromwich action liverpool relates comm...\n",
      "4    west from v liverpool review team news way wat...\n",
      "5    tomorrow west from v liverpool to 12 pm bit tr...\n",
      "6            ray would line of side wbaliv join u hour\n",
      "7    looking forward trip maggie tomorrow sit hand ...\n",
      "8    latest news side ahead trip hawthorne wbaliv t...\n",
      "9    big 1 next we need saturday ritual done go cla...\n",
      "Name: text_processed, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df['text_processed'] = df['clean_text'].apply(lambda x: tweet_preprocessing(x))\n",
    "\n",
    "print(df['text_processed'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['text_processed']\n",
    "y=df['interesting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 6 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 165 out of 180 | elapsed:   10.2s remaining:    0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
      " ...ax_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n",
      "0.7119113573407202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:   10.5s finished\n"
     ]
    }
   ],
   "source": [
    "#Creating a model using Tf-IDF vectoriser and LinearSVC\n",
    "#Used GridsearchCV for hyperparameter tuning\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "params = {\"tfidf__ngram_range\": [(1, 2)], \"svc__C\": [0.001,.01, .1, 1, 10, 100]}\n",
    "\n",
    "clf = Pipeline([(\"tfidf\", TfidfVectorizer(sublinear_tf=True, stop_words='english')), (\"svc\", LinearSVC())])\n",
    "\n",
    "gs = GridSearchCV(clf, params, cv=30, verbose=2, n_jobs=-1)\n",
    "gs.fit(x, y)\n",
    "print(gs.best_estimator_)\n",
    "print(gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>lang</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>user_listed_count</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>interesting</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game day make it ⚽️#31 Mo #WBALIV https://t.co...</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>en</td>\n",
       "      <td>O1Paul</td>\n",
       "      <td>False</td>\n",
       "      <td>7758</td>\n",
       "      <td>12008</td>\n",
       "      <td>1395</td>\n",
       "      <td>1395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>game day make it 31 mo wbaliv</td>\n",
       "      <td>game day make 31 mo wbaliv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>☁️9️\\n\\n@LFC are unbeaten in their last nine #...</td>\n",
       "      <td>296</td>\n",
       "      <td>2467</td>\n",
       "      <td>en</td>\n",
       "      <td>premierleague</td>\n",
       "      <td>True</td>\n",
       "      <td>17811702</td>\n",
       "      <td>999</td>\n",
       "      <td>91545</td>\n",
       "      <td>91545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9 are unbeaten in their last nine pl meetings ...</td>\n",
       "      <td>9 beaten last nine ll meeting we do wbaliv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Another big win for the Baggies against a weak...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>JPW_NBCSports</td>\n",
       "      <td>True</td>\n",
       "      <td>18786</td>\n",
       "      <td>9396</td>\n",
       "      <td>33749</td>\n",
       "      <td>33749</td>\n",
       "      <td>NaN</td>\n",
       "      <td>another big win for the baggies against a weak...</td>\n",
       "      <td>another big win maggie weakened liverpool side...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Early risers, we've got another one at 730AM t...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>en</td>\n",
       "      <td>LFCAtlanta</td>\n",
       "      <td>False</td>\n",
       "      <td>2683</td>\n",
       "      <td>4218</td>\n",
       "      <td>31447</td>\n",
       "      <td>31447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>early risers we ve got another one at 730am to...</td>\n",
       "      <td>early riser got another one 730am tomorrow mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#PL 🏴󠁧󠁢󠁥󠁮󠁧󠁿⚽\\nWest Bromwich Albion 🆚 Liverpool...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>en</td>\n",
       "      <td>JugadaDepCL</td>\n",
       "      <td>False</td>\n",
       "      <td>6585</td>\n",
       "      <td>978</td>\n",
       "      <td>13554</td>\n",
       "      <td>13554</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pl west bromwich albion liverpool relatos come...</td>\n",
       "      <td>ll west bromwich action liverpool relates comm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  retweet_count  \\\n",
       "0  Game day make it ⚽️#31 Mo #WBALIV https://t.co...              3   \n",
       "1  ☁️9️\\n\\n@LFC are unbeaten in their last nine #...            296   \n",
       "2  Another big win for the Baggies against a weak...              0   \n",
       "3  Early risers, we've got another one at 730AM t...              1   \n",
       "4  #PL 🏴󠁧󠁢󠁥󠁮󠁧󠁿⚽\\nWest Bromwich Albion 🆚 Liverpool...              8   \n",
       "\n",
       "   favorite_count lang user_screen_name  user_verified  user_followers_count  \\\n",
       "0              22   en           O1Paul          False                  7758   \n",
       "1            2467   en    premierleague           True              17811702   \n",
       "2               3   en    JPW_NBCSports           True                 18786   \n",
       "3               5   en       LFCAtlanta          False                  2683   \n",
       "4               5   en      JugadaDepCL          False                  6585   \n",
       "\n",
       "   user_favourites_count  user_listed_count  user_statuses_count interesting  \\\n",
       "0                  12008               1395                 1395         NaN   \n",
       "1                    999              91545                91545         NaN   \n",
       "2                   9396              33749                33749         NaN   \n",
       "3                   4218              31447                31447         NaN   \n",
       "4                    978              13554                13554         NaN   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0                      game day make it 31 mo wbaliv   \n",
       "1  9 are unbeaten in their last nine pl meetings ...   \n",
       "2  another big win for the baggies against a weak...   \n",
       "3  early risers we ve got another one at 730am to...   \n",
       "4  pl west bromwich albion liverpool relatos come...   \n",
       "\n",
       "                                      text_processed  \n",
       "0                         game day make 31 mo wbaliv  \n",
       "1         9 beaten last nine ll meeting we do wbaliv  \n",
       "2  another big win maggie weakened liverpool side...  \n",
       "3  early riser got another one 730am tomorrow mor...  \n",
       "4  ll west bromwich action liverpool relates comm...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessing all the tweets\n",
    "\n",
    "train['clean_text']=train['text'].apply(lambda x: clean_tweet(x))\n",
    "train['text_processed'] = train['clean_text'].apply(lambda x: tweet_preprocessing(x))\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(709,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting the categories of all the tweets\n",
    "\n",
    "predicted=gs.predict(train['clean_text'])\n",
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the dataframe of model 1 output\n",
    "\n",
    "final_predict = pd.DataFrame(predicted,columns=['interesting'])\n",
    "result = train[['text', 'user_screen_name','favorite_count', 'retweet_count']]\n",
    "tweets1 = pd.concat([result,final_predict],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2\n",
    "\n",
    "Here we use tweet features such as retweet_count, favorite_count, user_verified, user_followers_count, etc. for model building. \n",
    "We will build multiple binary classification models using various classification algorithm. Finally, we will use VotingClassifier function to create the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'retweet_count', 'favorite_count', 'lang', 'user_screen_name',\n",
       "       'user_verified', 'user_followers_count', 'user_favourites_count',\n",
       "       'user_listed_count', 'user_statuses_count', 'interesting', 'clean_text',\n",
       "       'text_processed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x=df[['retweet_count', 'favorite_count','user_verified', 'user_followers_count', 'user_favourites_count',\n",
    "       'user_listed_count']]\n",
    "df_y=df['interesting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(df_x)\n",
    "scaled = scaler.transform(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross validation parameters\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "kfold = KFold(n_splits=40, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 65.167\n"
     ]
    }
   ],
   "source": [
    "#Applying Support Vector Machine\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "l_svc = LinearSVC(random_state =42, C=0.0001)\n",
    "\n",
    "results_l_svc = cross_val_score(l_svc, scaled, df_y, cv=kfold, scoring='accuracy')\n",
    "print(\"Accuracy: %.3f\" %(results_l_svc.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.028\n"
     ]
    }
   ],
   "source": [
    "#Applying Logistic Regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression(penalty='l2',random_state=42)\n",
    "\n",
    "results_lr = cross_val_score(lr, scaled, df_y, cv=kfold, scoring='accuracy')\n",
    "print(\"Accuracy: %.3f\" %(results_lr.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 66.861\n"
     ]
    }
   ],
   "source": [
    "#Applying Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "results_gnb = cross_val_score(gnb, scaled, df_y, cv=kfold, scoring='accuracy')\n",
    "print(\"Accuracy: %.3f\" %(results_gnb.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 175 | elapsed:   11.3s remaining:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 175 out of 175 | elapsed:   12.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'n_estimators': 200}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter tuning for RandomForest with GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on approximte params  \n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [None, 1, 2, 4, 8],\n",
    "    'n_estimators': [5, 10, 20, 40, 70, 100, 200]\n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 5, n_jobs = -1, verbose = 2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(scaled, df_y)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.333\n"
     ]
    }
   ],
   "source": [
    "#Applying random forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, criterion='entropy',max_depth=None, oob_score=True, random_state=42, n_jobs=-1)\n",
    "\n",
    "results_rf = cross_val_score(rf, scaled, df_y, cv=kfold, scoring='accuracy')\n",
    "print(\"Accuracy: %.3f\" %(results_rf.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.667\n"
     ]
    }
   ],
   "source": [
    "#Applying VotingClassifier function\n",
    "#VotingClassifier function collects the output from each model and gives the mean of all for classification problems\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('l_svc', l_svc), ('LogReg', lr), ('Bayes', gnb), \n",
    "                                    ('forest', rf)], voting='hard')\n",
    "eclf.fit(scaled, df_y)\n",
    "results_eclf = cross_val_score(eclf, scaled, df_y, cv=kfold, scoring='accuracy',  n_jobs=-1)\n",
    "print(\"Accuracy: %.3f\" %(results_eclf.mean()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying trained model on all the relevant tweets\n",
    "\n",
    "test_x=train[['retweet_count', 'favorite_count','user_verified', 'user_followers_count', 'user_favourites_count',\n",
    "       'user_listed_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manth\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(709,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying trained model on all the relevant tweets\n",
    "\n",
    "predicted_2 = eclf.predict(scaler.transform(test_x))\n",
    "predicted_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the dataframe of predicted values\n",
    "\n",
    "final_predict_2 = pd.DataFrame(predicted_2,columns=['check_interesting'])\n",
    "tweets_check = pd.concat([tweets1,final_predict_2],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 + Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>interesting</th>\n",
       "      <th>check_interesting</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Happy Friday, Reds! We’ll see you bright and e...</td>\n",
       "      <td>LFCRaleigh</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gn family...sweet dreams...  Going to try and ...</td>\n",
       "      <td>sshlfc</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Brom have scored in each of their last se...</td>\n",
       "      <td>FPLUpdates_Tips</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West Brom vs Liverpool: Preview, Team News, an...</td>\n",
       "      <td>BloodsugarNatz</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>West Brom vs Liverpool: Preview, Team News, an...</td>\n",
       "      <td>LFCOffside</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text user_screen_name  \\\n",
       "5  Happy Friday, Reds! We’ll see you bright and e...       LFCRaleigh   \n",
       "6  Gn family...sweet dreams...  Going to try and ...           sshlfc   \n",
       "7  West Brom have scored in each of their last se...  FPLUpdates_Tips   \n",
       "8  West Brom vs Liverpool: Preview, Team News, an...   BloodsugarNatz   \n",
       "9  West Brom vs Liverpool: Preview, Team News, an...       LFCOffside   \n",
       "\n",
       "   favorite_count  retweet_count  interesting  check_interesting  \n",
       "5               3              0         True               True  \n",
       "6               3              1         True               True  \n",
       "7               3              0         True               True  \n",
       "8              36             16         True               True  \n",
       "9               2              1         True               True  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final Dataframe: it contains only tweets which are interessting as per both the models\n",
    "\n",
    "tweet_final=tweets_check[(tweets_check['check_interesting']==True) & (tweets_check['interesting']==True)]\n",
    "tweet_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function which return the top tweets based on the user requirements\n",
    "#It provides top tweets for two methods ('likes' or 'retweets')\n",
    "\n",
    "def top_tweets(method, n):\n",
    "    #method: 'likes' or 'retweets'\n",
    "    #n: total number of tweets\n",
    "    if 'retweets' in str(method):\n",
    "        interessting_tweets = tweet_final.sort_values(by='retweet_count', ascending=False).reset_index(drop=True)[['text','user_screen_name','favorite_count','retweet_count']].head(int(n))\n",
    "    else: interessting_tweets = tweet_final.sort_values(by='favorite_count', ascending=False).reset_index(drop=True)[['text','user_screen_name','favorite_count','retweet_count']].head(int(n))\n",
    "        \n",
    "    return interessting_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>🤡#JokeReferee of the weekend winner is Stuart ...</td>\n",
       "      <td>JokeReferee</td>\n",
       "      <td>450</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jeremycorbyn @jacindaardern @EmilyThornberry ...</td>\n",
       "      <td>Jezza4_PM</td>\n",
       "      <td>304</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>🙌 Darren Moore as WBA manager...\\n\\n- Unbeaten...</td>\n",
       "      <td>TheSportsman</td>\n",
       "      <td>721</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@jeremycorbyn \"He's put up with the most appal...</td>\n",
       "      <td>Jezza4_PM</td>\n",
       "      <td>273</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>🤡Stuart Atwell seen here clearly looking at an...</td>\n",
       "      <td>JokeReferee</td>\n",
       "      <td>191</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stuart Attwell didn't have the best of games. ...</td>\n",
       "      <td>jimbeglin</td>\n",
       "      <td>547</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Klopp just sent the interviewer for a hot dog ...</td>\n",
       "      <td>ZIYAAD_LFC</td>\n",
       "      <td>207</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Darren Moore has really got the players going ...</td>\n",
       "      <td>mrdanwalker</td>\n",
       "      <td>477</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This Hegazi is a right dirty little bastard, s...</td>\n",
       "      <td>crlfc74</td>\n",
       "      <td>217</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The greatest threat posed is unlawful evil int...</td>\n",
       "      <td>GoboMontaco</td>\n",
       "      <td>57</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text user_screen_name  \\\n",
       "0  🤡#JokeReferee of the weekend winner is Stuart ...      JokeReferee   \n",
       "1  @jeremycorbyn @jacindaardern @EmilyThornberry ...        Jezza4_PM   \n",
       "2  🙌 Darren Moore as WBA manager...\\n\\n- Unbeaten...     TheSportsman   \n",
       "3  @jeremycorbyn \"He's put up with the most appal...        Jezza4_PM   \n",
       "4  🤡Stuart Atwell seen here clearly looking at an...      JokeReferee   \n",
       "5  Stuart Attwell didn't have the best of games. ...        jimbeglin   \n",
       "6  Klopp just sent the interviewer for a hot dog ...       ZIYAAD_LFC   \n",
       "7  Darren Moore has really got the players going ...      mrdanwalker   \n",
       "8  This Hegazi is a right dirty little bastard, s...          crlfc74   \n",
       "9  The greatest threat posed is unlawful evil int...      GoboMontaco   \n",
       "\n",
       "   favorite_count  retweet_count  \n",
       "0             450            252  \n",
       "1             304            228  \n",
       "2             721            159  \n",
       "3             273            141  \n",
       "4             191             99  \n",
       "5             547             95  \n",
       "6             207             78  \n",
       "7             477             57  \n",
       "8             217             45  \n",
       "9              57             37  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final Result\n",
    "\n",
    "top_tweets('retweets', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can we increase the accuracy of above model:\n",
    "\n",
    " 1) By increasing the number of tagged tweets (training data). \n",
    "<br> 2) By increasing the quality of training data.\n",
    "<br> 3) By spending more time in cleaning each tweet text.\n",
    "<br> 4) By calculating Klout score for each user.\n",
    "<br> 5) By tracking media content of all the tweets such as GIFs, Images, Videos, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
